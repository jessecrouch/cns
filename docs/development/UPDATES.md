# UPDATES.md: CNS Webserver Milestone & Project Management

This document provides the strategic roadmap for evolving **Causal Narrative Script (CNS)** to handle complex tasks like webserver generation. Focus: **Common Lisp implementation**.

## Commander's Intent

**Objective**: Develop CNS into a robust, LLM-friendly language that enables reliable, unsupervised code generation for complex tasks like a webserver. Create a system where LLMs produce clear, executable CNS code with explicit causality, minimizing errors like hallucinations or implicit logic.

**Success Criteria**: CNS webserver that runs correctly (responds to `curl http://localhost:8080/`), generated by an LLM in ≤3 iterations, with traceable narrative steps.

**Flexibility**: You have full authority to prioritize, modify, or deviate from suggestions. This guide is a flexible framework aligned with making CNS a practical tool for LLMs.

---

## Current State

Minimal CNS interpreter in Common Lisp with:
- **Syntax**: `Story:`, `Given:`, `Step →`, `Because:`, `Effect:`, `If/Then/Otherwise`, `End:`
- **Features**: Basic expressions, lists, I/O (file/console), network effects (sockets), loops via `repeat from Step`
- **Execution**: Parses CNS to S-expressions, interprets with hash-table environment, traces steps
- **Real Socket Support**: Uses `usocket` for actual network I/O
- **Examples**: factorial, fibonacci, webserver (see `examples/demo-webserver.cns`)

---

## Goal: LLM-Generated Webserver

Enable LLMs to generate working webservers from prompts like "write a webserver". Example CNS output:

```
Story: Run a simple webserver
Given:
  port: Integer = 8080 [network port]
  routes: List = [("GET /", "Hello, World!")]
  server_socket: Socket
Step 1 → Create server_socket on port
  Effect: bind socket
  Because: Listen for incoming connections
Step 2 → Accept connection on server_socket
  Effect: network read
  Because: Receive client request
  Then: request = parse HTTP request
Step 3 → Find route matching request
  Because: Determine response based on URL
Step 4 → Send response to client
  Effect: network write
  Because: Return requested content
  Then: go to Step 2
End: Close server_socket
  Because: Clean up resources
```

**Why This Matters**: Proves CNS handles real-world complexity with explicit causality, enabling LLMs to tackle APIs, databases, games, etc.

---

## Project Management: Context Control

### Principles
- **Modular Tasks**: Small, focused units (one commit or session)
- **Narrative Documentation**: CNS-like commit messages ("Add HTTP parsing to enable routing")
- **Prioritization**: One phase at a time, defer non-critical tasks
- **Traceability**: Log progress clearly
- **Flexibility**: Adapt to feedback per Commander's Intent

### Task Structure
- **What**: Specific goal
- **Why**: Reason tied to project goals
- **How**: Brief approach (details in code/examples)
- **Test**: Verification step

---

## Development Roadmap

### Phase 1: Language Features Enhancement (1-2 weeks)

**Tasks**:
1. **Socket Support** ✓ (DONE - using `usocket`)
   - Support `Socket` type and effects (bind, accept, send, close)
   - See `src/cns.lisp` implementation
   - Real network I/O with SBCL sockets

2. **HTTP Parsing** ✓ (DONE - enhanced implementation)
   - Parse HTTP requests (method, path, query params, headers, body)
   - Route matching with wildcards (`/files/*`) and named params (`/users/:id`)
   - Response builders: `build-http-response()`, `build-json-response()`, `build-error-response()`
   - Test: 39/39 regression tests passing (15 new HTTP tests)
   - See: `src/cns.lisp:parse-http-request()`, `match-route-pattern()`

3. **Advanced Control Flow** ⏳ (PARTIALLY DONE)
   - Route matching implemented (wildcards, named params)
   - TODO: Formalize `For each` syntax for list iteration
   - TODO: Add `Match` statement for pattern matching
   - Test: Route matching validated in regression tests

4. **Error Handling** ⏳ (PLANNED)
   - TODO: Formalize `Error:` blocks for socket failures, invalid requests
   - Currently using Common Lisp `handler-case` in interpreter
   - Test: Simulate failure, verify error block execution

### Phase 2: LLM Integration (2-3 weeks)

**Tasks**:
5. **Prompt Templates** ✓ (DONE - 50% complete)
   - Created webserver generation prompts in `prompts/`
   - Templates: `webserver-template.md`, `webserver-generation-prompt.md`
   - Includes syntax guide and best practices
   - TODO: Update prompts to include new HTTP features

6. **Dataset Creation** ✓ (DONE - 50% complete)
   - Created 126 webserver examples in `dataset/webserver-examples-extended.json`
   - Examples cover single-route, multi-route, query params, errors
   - Additional 30 general CNS examples in `dataset/cns-examples.json`
   - TODO: Add examples using new HTTP parsing features
   - Test: All examples validated successfully

7. **Validation System** ✓ (DONE - comprehensive)
   - Built `src/cns-validator.lisp` (387 lines)
   - Checks: syntax, semantics, structure, causality, undefined variables
   - Command-line tool: `src/cns-validate`
   - Test: 29/29 CNS files validate successfully
   - Automated test runner: `tests/run-validation-tests.sh`
   - Documentation: `docs/development/TESTING.md`

8. **Feedback Loop** ⏳ (PLANNED)
   - TODO: Re-prompt on errors with specific fixes
   - Validator provides detailed error messages for LLM feedback
   - TODO: Implement automatic retry with error context
   - Limit to 3 retries
   - Test: Simulate error, verify correction

### Phase 3: Testing & Validation (2 weeks)

**Tasks**:
9. **Test Suite** ✓ (DONE - comprehensive)
   - Created regression test suite: `tests/regression-tests.lisp` (39 tests)
   - Tests cover: parsing, HTTP parsing, route matching, list ops, file I/O
   - 15 new HTTP tests: query params, headers, body, wildcards, named params
   - All 29 CNS examples validate and execute
   - Test runners: `tests/run-all-tests.sh`, `tests/run-validation-tests.sh`
   - LLM execution tests: `tests/llm-tests/` (10 scenarios)
   - Results: 100% test pass rate

10. **Benchmarks** ⏳ (PLANNED)
    - TODO: Compare CNS vs. Python/Flask for error rate, iterations
    - Initial data: Grok-2 achieved 100% success on sum-range task
    - TODO: Prove CNS advantage in reducing LLM errors
    - TODO: Document results in `docs/development/BENCHMARKS.md`

### Phase 4: Unsupervised Robustness (1-2 weeks)

**Tasks**:
11. **Sandbox Execution**
    - Run CNS in isolated environment (Docker)
    - Add timeout handling for safety
    - Catch crashes gracefully

12. **Self-Correction**
    - Auto-retry on errors with refined prompts
    - Enable autonomous debugging
    - Cap at 3 retries

---

## Timeline

- **Phase 1**: 1-2 weeks (language features) - Resources: `usocket`, `cl-ppcre`
- **Phase 2**: 2-3 weeks (LLM integration) - Resources: LLM APIs, JSON
- **Phase 3**: 2 weeks (testing/benchmarks) - Resources: Test frameworks
- **Phase 4**: 1-2 weeks (robustness) - Resources: Docker

**Total**: 6-9 weeks part-time

---

## Implementation Notes

### Resources
- **Socket I/O**: `usocket` library (already integrated)
- **HTTP Parsing**: `cl-ppcre` for regex
- **Testing**: FiveAM or similar
- **Execution**: SBCL (Steel Bank Common Lisp)

### Code Organization
- **Interpreter**: `src/cns.lisp`
- **Examples**: `examples/` (especially `demo-webserver.cns`)
- **Tests**: `tests/llm-tests/`
- **Prompts**: `prompts/`
- **Dataset**: `dataset/`

### Commit Style
Use CNS-style narrative commits:
- "Add HTTP parsing to enable webserver routing"
- "Implement error blocks for robust failure handling"

---

## Recent Progress (Oct 2025)

### Completed
1. ✅ **Testing Infrastructure** - Comprehensive validation and regression testing
2. ✅ **HTTP Parsing Enhancement** - Query params, headers, body, route patterns
3. ✅ **Route Matching** - Wildcards (`/files/*`) and named params (`/users/:id`)
4. ✅ **Response Builders** - JSON, HTML, error responses
5. ✅ **Validation System** - Pre-execution checks, detailed error reporting
6. ✅ **Dataset Expansion** - 156 total examples (126 webserver + 30 general)

### Test Results
- **Regression tests**: 39/39 passing (100%)
- **Validation tests**: 29/29 passing (100%)
- **LLM generation**: Grok-2 achieved 100% on sum-range task

## Next Immediate Steps

### Option A: Real HTTP Execution Testing
1. Debug socket creation issues (EADDRINUSE errors)
2. Test `examples/demo-webserver.cns` with actual curl requests
3. Verify backward compatibility with existing examples
4. Test new HTTP parsing features in live webserver

### Option B: Complete Phase 1 Features
1. Formalize `For each` loop syntax for list iteration
2. Add `Match` statement for pattern matching
3. Implement `Error:` blocks for explicit error handling
4. Update examples to use new control flow

### Option C: Enhance LLM Integration (Phase 2)
1. Update prompt templates with new HTTP features
2. Add examples using query params and path params to dataset
3. Test LLM webserver generation with enhanced features
4. Implement feedback loop for error correction

### Recommendation
**Start with Option A** - Validate that HTTP enhancements work in real execution before adding more features or generating more examples.

---

## Why This Approach

- **Webserver Test**: Validates CNS on complex, real-world task
- **Lisp Implementation**: Homoiconicity enables rapid iteration
- **LLM Integration**: Prompts + validation enable unsupervised coding
- **Modular Tasks**: Keeps context manageable
- **Flexibility**: Empowers adaptation to new insights

Let's make CNS the go-to language for LLM coding!
