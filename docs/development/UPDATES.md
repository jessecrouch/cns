# UPDATES.md: Causal Narrative Script (CNS) Project - Webserver Milestone and Project Management Guide

This document updates the **Causal Narrative Script (CNS)** project, a programming language designed for Large Language Models (LLMs) to generate, understand, and refine code with minimal errors, particularly for unsupervised tasks. Our goal is to evolve CNS to handle complex tasks like generating a working webserver from a prompt like "write a webserver." The focus remains on the **Common Lisp implementation** due to its homoiconicity, but this guide is for your coding AI tool (e.g., OpenCode or xAI fast code) to drive development, manage the project, and ensure clarity for both you (the developer) and the LLM. It builds on our progress—a prototype with I/O and lists built in an evening—and provides a roadmap to achieve the webserver milestone while addressing your vision of solving LLM coding challenges.

Additionally, this document includes **project management instructions** to handle the potentially large context size, breaking tasks into manageable, understandable parts for you and the LLM. It incorporates a **Commander’s Intent** to give the AI flexibility while keeping the project aligned with your goals.

---

## Commander’s Intent
The primary objective is to develop CNS into a robust, LLM-friendly language that enables reliable, unsupervised code generation for complex tasks like a webserver. The intent is to create a system where LLMs can produce clear, executable CNS code with explicit causality, minimizing errors like hallucinations or implicit logic. You, as the project lead, have full authority to prioritize tasks, modify approaches, or deviate from specific suggestions as you see fit. The AI should treat this guide as a flexible framework, adapting to your preferences, new insights, or project constraints while staying true to the goal of making CNS a practical tool for LLMs. Success is a CNS webserver that runs correctly (e.g., responds to `curl http://localhost:8080/`), generated by an LLM in ≤3 iterations, with traceable, narrative steps.

---

## Current State
We’ve built a minimal CNS interpreter in Common Lisp, capable of parsing and executing simple programs like factorial, with support for:
- **Syntax**: `Story:`, `Given:`, `Step →`, `Because:`, `Effect:`, `If/Then/Otherwise`, `End:`.
- **Features**: Basic expressions (multiply, assign), lists (append), I/O (mock file/console), loops via `repeat from Step`.
- **Execution**: Parses CNS to S-expressions, interprets with a hash-table environment, and traces steps for auditability.
- **Example** (Factorial):
  ```
  Story: Compute factorial of a positive integer
  Given:
    n: Integer [≥ 1] = 5
    result: Integer = 1
  Step 1 → Multiply result by n
    Because: n contributes to the product
    Then: n becomes n - 1
  Step 2 → If n > 1, repeat from Step 1
    Because: we need to include all integers down to 1
    Otherwise: go to End
  End:
    Return result
    Because: all factors have been multiplied
  ```
  - Output: 120, with step-by-step traces.

The prototype validates CNS’s core concept: narrative code with explicit causality reduces LLM errors. However, it needs enhancements for complex tasks like a webserver (e.g., network I/O, string parsing) and better LLM integration for unsupervised generation.

---

## Goal: LLM-Generated Webserver
We aim to evolve CNS so an LLM can be prompted with “write a webserver” and produce a working CNS implementation, such as:
```
Story: Run a simple webserver
Given:
  port: Integer = 8080 [network port]
  routes: List[Tuple[String, String]] = [("GET /", "Hello, World!")] [URL to response]
  server_socket: Socket [network listener]
Step 1 → Create server_socket on port
  Effect: bind socket
  Because: Listen for incoming connections
Step 2 → Accept connection on server_socket
  Effect: network read
  Because: Receive client request
  Then: request = parse HTTP request
Step 3 → Find route in routes matching request.url and request.method
  Because: Determine response based on URL
  If found → go to Step 4
  Otherwise → go to Step 5
Step 4 → Send response from route to client
  Effect: network write
  Because: Return requested content
  Then: go to Step 2
Step 5 → Send "404 Not Found" to client
  Effect: network write
  Because: No matching route
  Then: go to Step 2
Error:
  Return "Server error"
  Effect: log error
  Because: Handle unexpected failure
End:
  Close server_socket
  Because: Clean up resources
```
**Success Criteria**:
- Runs in the Lisp interpreter, responds to `curl http://localhost:8080/` with “Hello, World!”.
- Handles basic HTTP (GET), errors (404), and cleanup.
- LLM generates this in ≤3 iterations (initial attempt + corrections).

This supports your theory that CNS’s narrative structure can solve LLM coding issues (e.g., hallucinations, implicit logic) by making steps clear and justifiable, especially for unsupervised tasks.

---

## Why This Matters
CNS addresses LLM coding weaknesses:
- **Ambiguity**: Traditional languages (e.g., Python) allow implicit state or side effects, causing errors. CNS’s `Because:` and `Effect:` enforce clarity.
- **Hallucinations**: LLMs invent invalid code (e.g., undefined variables). CNS’s structure and validation catch these early.
- **Unsupervised Challenges**: LLMs struggle to self-correct. CNS’s traceability enables error-driven refinement.
- **Complex Tasks**: A webserver requires I/O, routing, and error handling—CNS’s narrative flow simplifies these for LLMs.

Achieving a webserver proves CNS can handle real-world complexity, enabling applications like APIs, databases, or games.

---

## Project Management Instructions
The CNS project has a potentially large context size due to its feature set, LLM integration, and testing needs. To keep it manageable for you (the developer) and the LLM, we’ll break it into modular, standalone tasks that align with CNS’s narrative style. Each task should be small, self-contained, and include a clear “Because” to explain its purpose, mirroring CNS’s structure. This ensures both you and the LLM can understand and track progress without overwhelming context.

### Principles for Managing Context
- **Modular Tasks**: Divide work into small, focused units (e.g., “Add socket support,” “Write 5 webserver examples”). Each task should fit in a single commit or coding session.
- **Narrative Documentation**: Use CNS-like comments in code and commits (e.g., “Step: Add HTTP parsing Because: Enable routing”).
- **Prioritization**: Focus on one phase at a time (e.g., language features first, then LLM integration). Defer non-critical tasks (e.g., advanced optimizations).
- **Traceability**: Log progress in this file with clear updates (e.g., “Completed socket effects, testing multi-route”).
- **Flexibility**: The LLM should adapt tasks to your feedback, new ideas, or constraints, per the Commander’s Intent.
- **Context Reduction**: For each task, provide only the relevant CNS example, code snippet, or prompt. Avoid overloading with full project history unless needed.

### How to Break Down Tasks
- **Task Structure**:
  - **What**: Specific goal (e.g., “Implement socket effects”).
  - **Why**: Reason, tied to project goals (e.g., “Enable webserver I/O”).
  - **How**: Suggested code or approach (e.g., “Use `usocket` in `eval-expr`”).
  - **Test**: Verification step (e.g., “Run CNS snippet, check socket binds”).
- **Size**: Aim for tasks completable in 1-2 hours (e.g., one function or test case).
- **Grouping**: Organize tasks by phase (language features, LLM integration, testing, robustness).
- **LLM Interaction**: Feed the LLM one task at a time with relevant context (e.g., CNS webserver example, prior Lisp code). If context grows, summarize or reference this file.

### Example Task Breakdown
- **Task**: Add socket support.
  - **What**: Extend `eval-expr` to handle `Socket` type and effects (`CREATE`, `ACCEPT`, `SEND`).
  - **Why**: Webservers need network I/O; explicit effects reduce LLM errors.
  - **How**: Use `usocket` in Lisp (see code below).
  - **Test**: Run CNS snippet: `Create server_socket on 8080`, verify socket binds.
- **Task**: Write 5 webserver examples.
  - **What**: Create CNS code for single-route, multi-route, etc.
  - **Why**: Dataset trains LLMs to generate webservers.
  - **How**: Write CNS manually, save to JSON.
  - **Test**: Parse and run each example in interpreter.

---

## What Needs to Be Done
Below are prioritized tasks to reach the webserver milestone, broken into manageable parts with reasoning and actions. These are suggestions—per the Commander’s Intent, you can modify, reorder, or ignore them as needed.

### 1. Enhance CNS Language Features
CNS needs network I/O, string parsing, and control flow for a webserver.

#### Tasks
- **Task 1: Socket Support**
  - **What**: Add `Socket` type and effects (`bind socket`, `network read`, `network write`, `close socket`).
  - **Why**: Webservers need socket operations; explicit effects ensure LLMs declare them.
  - **How**:
    ```lisp
    (defun eval-expr (expr env)
      (cond ((stringp expr)
             (let ((parts (split-string expr #\Space)))
               (case (intern (string-upcase (car parts)))
                 (CREATE (if (string= (cadr parts) "server_socket")
                             (setf (gethash (caddr parts) env)
                                   (usocket:socket-listen "localhost" (eval-expr (cadddr parts) env)))))
                 (ACCEPT (setf (gethash (caddr parts) env)
                               (usocket:socket-accept (gethash (cadr parts) env))))
                 (SEND (usocket:socket-send (gethash (cadr parts) env) (eval-expr (caddr parts) env)))
                 (t (gethash expr env))))
            (t (gethash expr env))))
    ```
  - **Test**: Run CNS: `Create server_socket on 8080`, verify socket binds with `netstat`.
  - **Action**: Implement in `eval-expr`, test with `usocket` in SBCL.

- **Task 2: HTTP Parsing**
  - **What**: Support parsing HTTP requests (method, URL, query params).
  - **Why**: Parsing enables routing; a helper simplifies LLM generation.
  - **How**:
    ```lisp
    (defun parse-http (data)
      (cl-ppcre:register-groups-bind (method url)
          ("^(\\w+)\\s+([^\\s]+)\\s+HTTP" data)
        `(("method" ,method) ("url" ,url))))
    ```
  - **Test**: Parse “GET / HTTP/1.1” → `(("method" "GET") ("url" "/"))`.
  - **Action**: Add `parse-http` to interpreter, test in SBCL.

- **Task 3: Advanced Control Flow**
  - **What**: Enhance `For each` for lists and `Match` for routing.
  - **Why**: Webservers need dynamic routing; explicit loops reduce errors.
  - **How**: Parse `For each route in routes, match request.url` into `(for-each route routes (match ...))`, use `loop`.
  - **Test**: Run CNS with route list, verify matching.
  - **Action**: Extend parser and `eval-expr`.

- **Task 4: Error Handling**
  - **What**: Formalize `Error:` blocks for socket failures, invalid requests.
  - **Why**: Ensures reliable servers, traceable for LLMs.
  - **How**:
    ```lisp
    (handler-case
        (interpret-cns ast)
      (error (e) (format t "Error: ~A~%" e) (eval-error-block ast env)))
    ```
  - **Test**: Simulate socket failure, verify jumps to `Error:`.
  - **Action**: Implement error block parsing and execution.

- **Time Estimate**: ~1 week (2-3 days for sockets/parsing, 1-2 days for control flow/errors).

### 2. LLM Integration for Webserver Generation
Enable LLMs to generate webserver CNS code from a prompt.

#### Tasks
- **Task 5: Prompt Template**
  - **What**: Design a prompt for consistent CNS output.
  - **Why**: Guides LLMs to produce complete, valid CNS.
  - **How**:
    ```
    Given a task: {TASK}
    Write CNS code to:
    - Define a Story with clear steps
    - Use Given: for variables (e.g., port, routes, socket)
    - Include Step: with Because: and Effect:
    - Handle errors with Error: block
    - End with cleanup
    Example: [Insert webserver CNS above]
    Output only CNS code.
    ```
  - **Test**: Prompt with “webserver on port 8000,” verify CNS structure.
  - **Action**: Store in `prompts.lisp`, test in SBCL.

- **Task 6: Dataset Creation**
  - **What**: Create 50-100 CNS webserver examples (single route, multi-route, query params).
  - **Why**: Trains LLMs to map tasks to CNS, reducing hallucinations.
  - **How**:
    ```lisp
    (defun generate-example (task output-file)
      (with-open-file (f output-file :direction :output)
        (format f "Task: ~A~%CNS:~%~A~%" task (generate-cns task))))
    ```
  - **Test**: Generate 5 examples, verify they parse/run.
  - **Action**: Save to JSON/CSV.

- **Task 7: Validation**
  - **What**: Check CNS for completeness (vars, `Because:`, effects).
  - **Why**: Catches errors before execution, critical for unsupervised coding.
  - **How**:
    ```lisp
    (defun validate-cns (ast)
      (let ((vars (mapcar #'cadr (cadr (assoc 'given ast))))
            (steps (remove-if-not (lambda (x) (eq (car x) 'step)) ast)))
        (dolist (step steps)
          (unless (assoc 'because (cddr step))
            (error "Missing Because in Step ~A" (cadr step)))
          t)))
    ```
  - **Test**: Validate webserver CNS, catch missing `server_socket`.
  - **Action**: Implement validation, integrate with interpreter.

- **Task 8: Feedback Loop**
  - **What**: Re-prompt on errors (e.g., missing `server_socket`).
  - **Why**: Enables unsupervised refinement.
  - **How**: Parse errors, re-prompt:
    ```
    Error: {ERROR}
    Fix CNS code, ensuring all sockets initialized and effects declared.
    ```
  - **Test**: Simulate error, verify correction in ≤3 tries.
  - **Action**: Build error parser, limit retries.

- **Time Estimate**: ~2-3 weeks (1 week for prompts/dataset, 1-2 weeks for validation/feedback).

### 3. Testing and Validation
Ensure the LLM-generated webserver works and outperforms alternatives.

#### Tasks
- **Task 9: Test Suite**
  - **What**: Test single route, multi-route, query params, 404, socket errors.
  - **Why**: Verifies functionality, catches regressions.
  - **How**:
    ```lisp
    (def-test webserver-test ()
      (let ((cns-code "..."))  ; [Insert webserver CNS]
        (is (string= (simulate-http (interpret-cns (parse-cns cns-code)) "GET /") "Hello, World!"))
        (is (string= (simulate-http (interpret-cns (parse-cns cns-code)) "GET /missing") "404 Not Found"))))
    ```
  - **Test**: Run CNS, verify with `curl`.
  - **Action**: Write 5-10 tests, mock HTTP with `usocket`.

- **Task 10: Benchmarks**
  - **What**: Compare CNS vs. Python (e.g., Flask) for error rate, iterations.
  - **Why**: Proves CNS’s advantage in reducing LLM errors.
  - **How**: Script to run CNS/Python outputs, log metrics (correctness, hallucinations).
  - **Test**: Generate both, compare errors.
  - **Action**: Implement benchmark script.

- **Time Estimate**: ~2 weeks (1 week for tests, 1 week for benchmarks).

### 4. Unsupervised Robustness
Enable LLMs to generate and refine CNS webservers without human input.

#### Tasks
- **Task 11: Sandbox**
  - **What**: Run CNS in Dockerized SBCL to catch crashes/timeouts.
  - **Why**: Safe execution for unsupervised runs.
  - **How**:
    ```lisp
    (handler-case
        (usocket:with-server-socket (s (gethash "server_socket" env))
          (usocket:with-timeout (10) ...))
      (error (e) (format t "Network error: ~A~%" e)))
    ```
  - **Test**: Simulate crash, verify containment.
  - **Action**: Set up Docker, add timeout handling.

- **Task 12: Self-Correction**
  - **What**: Re-prompt on errors (e.g., “No route for POST”).
  - **Why**: Mimics human debugging, enables autonomy.
  - **How**: Parse errors, re-prompt, cap at 3 retries.
  - **Test**: Simulate missing route, verify correction.
  - **Action**: Implement retry logic.

- **Time Estimate**: ~1-2 weeks.

---

## Timeline
- **Phase 1 (1-2 weeks)**: Language features (Tasks 1-4). Resources: `usocket`, `cl-ppcre`.
- **Phase 2 (2-3 weeks)**: LLM integration (Tasks 5-8). Resources: xAI API, JSON/CSV.
- **Phase 3 (2 weeks)**: Testing/benchmarks (Tasks 9-10). Resources: FiveAM, mock HTTP.
- **Phase 4 (1-2 weeks)**: Unsupervised robustness (Tasks 11-12). Resources: Docker.

**Total**: ~6-9 weeks part-time. Your prototype’s speed suggests faster progress with AI tools.

---

## How to Proceed
- **Follow Commander’s Intent**: Prioritize tasks as you see fit, adapting to new ideas or constraints. The AI should align with your vision, not strictly follow these suggestions.
- **Work on One Task at a Time**: Start with Task 1 (socket support), then Task 2, etc. Feed the LLM the task’s “What,” “Why,” “How,” and “Test” sections.
- **Generate Code**:
  - Implement socket support with `usocket`, parsing with `cl-ppcre`.
  - Extend parser for `For each`, `Match`, `Error:`.
  - Add validation and error parsing to `interpret-cns`.
- **Create Dataset**: Generate 10 CNS webserver variants, save to JSON/CSV.
- **Test Prompts**: Prompt LLM with “write a webserver on port 8080,” validate output, run in SBCL, test with `curl`.
- **Set Up Sandbox**: Configure Dockerized SBCL, implement retry logic.
- **Document**:
  - Commit with CNS-style messages: “Step: Add socket support Because: Enable webserver I/O.”
  - Update this file with progress (e.g., “Completed socket effects, testing multi-route”).
  - Share snippets on X (#CNSLang) for feedback.
- **Context Management**: For each task, provide the LLM with:
  - Task description and code snippet.
  - Relevant CNS example (e.g., webserver).
  - Reference to this file for full context if needed.
  - Avoid overloading with prior tasks unless relevant (e.g., use Task 1 output for Task 2).

---

## Reasoning for This Approach
- **Why Webserver?**: Tests CNS on a complex task (I/O, logic, errors), proving its value.
- **Why Lisp?**: Homoiconicity and macros enable rapid iteration, aligning with CNS.
- **Why LLM Integration?**: Prompts, validation, and feedback enable unsupervised coding.
- **Why Modular Tasks?**: Small, clear tasks keep context manageable for you and the LLM.
- **Why Flexibility?**: Commander’s Intent empowers you to adapt, ensuring the project fits your vision.

---

## Next Immediate Steps
1. **Task 1: Socket Support**: Implement `Socket` type and effects using `usocket`.
2. **Task 2: HTTP Parsing**: Add `parse-http` with `cl-ppcre`.
3. **Task 5: Prompt Template**: Test “webserver on port 8080” with LLM, validate CNS.
4. **Document**: Update this file with progress.

Let’s make CNS the go-to language for LLM coding! If you need a specific Lisp function, CNS example, or prompt, I can provide it to keep momentum. You’re in charge—steer the project as you see fit!