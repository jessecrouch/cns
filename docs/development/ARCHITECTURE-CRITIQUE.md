# CNS Lisp Interpreter: Code Critique & Analysis

## Overview
- **File**: `src/cns.lisp` (4,539 lines, 67 functions)
- **Language**: Common Lisp
- **Purpose**: Interpreter for CNS (Causal Narrative Script)

---

## CRITICAL ARCHITECTURAL PROBLEMS

### 1. **The "God Function" Anti-Pattern** âš ï¸âš ï¸âš ï¸

**`eval-expr`**: 562 lines (~12% of entire codebase)
**`apply-effect`**: 871 lines (~19% of entire codebase)

These two functions contain **31% of your entire codebase**. This is a massive code smell.

**Problems:**
- Single monolithic `cond` with 50+ branches
- Order-dependent pattern matching (your exact complaint!)
- Impossible to reason about precedence without reading 500+ lines
- Every new feature requires modifying a 500-line function
- High coupling - everything touches everything

**Why this happens in interpreters:**
Classic "recursive descent parser" structure where one function handles all expression types. This works for toy languages but doesn't scale.

---

### 2. **Order-Dependent Pattern Matching** ðŸ”¥

The `eval-expr` function uses a giant `cond` where **ORDER MATTERS CRITICALLY**:

```lisp
(cond
  ;; String literals MUST come first
  ((quoted-string? ...) ...)
  
  ;; Filepath literals MUST come before operators  
  ((starts-with "/" ...) ...)
  
  ;; Math functions MUST come before arithmetic
  ((starts-with "SQRT OF" ...) ...)
  
  ;; Comparisons MUST come before arithmetic
  ((search "=" ...) ...)
  
  ;; Arithmetic MUST come before literals
  ((search "+" ...) ...)
  
  ;; Variables come last
  ((variable? ...) ...))
```

**Why this is bad:**
- No explicit precedence table
- Precedence is implicit in code order
- Adding new operators requires understanding ALL existing order constraints
- Comments like "MUST come BEFORE X" are red flags
- You literally just hit this bug with filepaths!

---

### 3. **String-Based Parsing Without a Lexer** ðŸ˜±

You're doing textual pattern matching on raw strings:
- `(search "=" trimmed)`
- `(starts-with (string-upcase trimmed) "SQRT OF ")`
- `(position #\- trimmed)`

**Problems:**
- No tokenization phase
- Can't distinguish `/tmp/test-file.txt` from `a - b` without special cases
- Quoted strings require guards on EVERY operator
- Regex patterns break operators
- No context about what characters mean

**Proper approach:**
```
Source â†’ Lexer â†’ Tokens â†’ Parser â†’ AST â†’ Evaluator
```

**Current approach:**
```
Source â†’ eval-expr (does everything at once) â†’ Result
```

---

### 4. **Guard Explosion** ðŸ›¡ï¸ðŸ›¡ï¸ðŸ›¡ï¸

Look at the `-` operator (lines ~1956-1978):

```lisp
((and (search "-" trimmed)
      ;; Guard 1: Not a quoted string
      (not (and (> (length trimmed) 1)
               (char= (char trimmed 0) #\")
               (char= (char trimmed (1- (length trimmed))) #\")))
      ;; Guard 2: Not a filepath
      (not (and (> (length trimmed) 0)
               (char= (char trimmed 0) #\/)))
      ;; Guard 3-7: Not in special contexts
      (not (starts-with "FORMAT TIME "))
      (not (starts-with "ADD DAYS "))
      (not (starts-with "ADD HOURS "))
      (not (starts-with "ADD MINUTES "))
      (not (starts-with "REPLACE "))
      ;; Guard 8: Has left operand
      (let ((minus-pos (position #\- trimmed)))
        (and minus-pos
             (> minus-pos 0)
             (> (length (trim (subseq trimmed 0 minus-pos))) 0))))
 ...)
```

**This is unmaintainable.** Every time you add a new construct, you need to add guards to EVERY operator.

---

### 5. **No Separation of Concerns**

The same function handles:
- Literal values (numbers, strings, booleans)
- Variable lookup
- Operator precedence  
- Function calls
- Built-in functions (SQRT, ABS, etc.)
- Special forms (becomes, NOW(), etc.)
- List literals
- Type coercion

This violates the Single Responsibility Principle catastrophically.

---

## WHAT A BETTER ARCHITECTURE LOOKS LIKE

### Option 1: **Multi-Phase Interpreter**

```lisp
;; Phase 1: Tokenize
(defun tokenize (source)
  "Convert source string into tokens"
  ;; Returns: '((:NUMBER 42) (:OPERATOR "+") (:NUMBER 10))
  ...)

;; Phase 2: Parse into AST
(defun parse (tokens)
  "Build Abstract Syntax Tree from tokens"
  ;; Returns: '(:BINOP :+ (:LIT 42) (:LIT 10))
  ...)

;; Phase 3: Evaluate AST
(defun eval-ast (ast env)
  "Evaluate AST node - much simpler dispatch"
  (case (car ast)
    (:LIT (cadr ast))
    (:VAR (gethash (cadr ast) env))
    (:BINOP (apply-binop (cadr ast) 
                         (eval-ast (caddr ast) env)
                         (eval-ast (cadddr ast) env)))))
```

**Benefits:**
- Each phase is testable independently
- Token stream makes operator matching trivial
- AST makes precedence explicit
- Can add optimizations between phases

---

### Option 2: **Pratt Parser** (Middle Ground)

If you want to keep single-pass parsing:

```lisp
(defun parse-expr (input &optional (min-bp 0))
  "Pratt parser with explicit binding power for precedence"
  (let ((lhs (parse-prefix input)))
    (loop while (>= (binding-power (peek input)) min-bp)
          do (setf lhs (parse-infix lhs input)))
    lhs))

(defun binding-power (op)
  "Explicit precedence table"
  (case op
    ((* /) 40)
    ((+ -) 30)
    ((< > <= >=) 20)
    ((= !=) 10)))
```

**Benefits:**
- Explicit precedence (one table, not scattered through code)
- Still single-pass
- Much easier to extend
- Google "Pratt parser" - widely used for exactly this

---

### Option 3: **Dispatch Tables** (Minimal Refactor)

Even without full rewrite, you could extract:

```lisp
(defvar *literal-handlers* 
  (list 
    #'handle-string-literal
    #'handle-filepath-literal
    #'handle-number-literal
    #'handle-list-literal))

(defvar *operator-handlers*
  '((= . 10)  ; precedence level
    (+ . 20)
    (* . 30)))

(defun eval-expr (expr env)
  (or (try-handlers *literal-handlers* expr env)
      (try-operators *operator-handlers* expr env)
      (lookup-variable expr env)))
```

---

## SPECIFIC CODE SMELLS

### 1. **Magic Numbers Everywhere**
```lisp
(subseq trimmed 8)  ;; Why 8? 
(+ to-pos 4)         ;; Why 4?
(+ becomes-pos 9)    ;; Why 9?
```

Should be:
```lisp
(let ((keyword-length (length "SQRT OF ")))
  (subseq trimmed keyword-length))
```

### 2. **Duplicated Guard Logic**

The "not quoted string" guard appears ~20 times:
```lisp
(not (and (> (length trimmed) 1)
         (char= (char trimmed 0) #\")
         (char= (char trimmed (1- (length trimmed))) #\")))
```

Extract to:
```lisp
(defun quoted-string-p (str)
  (and (> (length str) 1)
       (char= (char str 0) #\")
       (char= (char str (1- (length str))) #\")))
```

### 3. **No Error Recovery**

When parsing fails, you just fall through. No position information, no "expected X but got Y".

### 4. **Mutation and Side Effects**

`becomes` modifies environment during expression evaluation:
```lisp
(setf (gethash var-name env) result)
```

This makes eval-expr impure and harder to reason about.

---

## HOW TO FIX (Incremental Path)

### Step 1: Extract Helper Predicates (1-2 hours)
```lisp
(defun quoted-string-p (s) ...)
(defun filepath-p (s) ...)
(defun keyword-expr-p (s keyword) ...)
```

### Step 2: Extract Operator Handlers (2-4 hours)
```lisp
(defun eval-arithmetic (op left right env) ...)
(defun eval-comparison (op left right env) ...)
```

### Step 3: Build Precedence Table (1 hour)
```lisp
(defvar *operator-precedence*
  '((= . 10)
    (+ . 20)
    (* . 30)))
```

### Step 4: Add Tokenizer (4-8 hours)
This is the big one but worth it.

### Step 5: Build Proper Parser (8-16 hours)
Returns AST instead of evaluating directly.

---

## THE ROOT CAUSE

You built a **single-pass string-munging interpreter**. This is fine for:
- Educational toys (under 10 operators)
- DSLs with very simple syntax
- Quick prototypes

But CNS has:
- 15+ operators
- Complex precedence rules
- String literals, regex, filepaths
- Special forms (becomes, function calls)
- Growing feature set

**You've outgrown the architecture.**

---

## COMPARISON TO OTHER LANGUAGES

### **Python's Approach:**
1. Tokenizer (1000 lines)
2. Parser (generates AST - 3000 lines)
3. Compiler (AST â†’ bytecode - 5000 lines)
4. Evaluator (VM - 2000 lines)

Total: ~11,000 lines, but each phase is simple

### **Your Approach:**
1. eval-expr (does everything - 562 lines)
2. apply-effect (does everything - 871 lines)

Total: ~1400 lines, but each function is complex

**Trade-off:** Your approach is more compact but less maintainable.

---

## RECOMMENDATIONS

### ðŸŸ¢ **Quick Wins (Do This Week)**
1. Extract `quoted-string-p`, `filepath-p`, etc.
2. Add comments with precedence levels in eval-expr
3. Document the expected order in a comment block
4. Write unit tests for operator precedence

### ðŸŸ¡ **Medium Term (Do This Month)**  
1. Build explicit operator precedence table
2. Extract operator handlers into separate functions
3. Consider Pratt parser approach

### ðŸ”´ **Long Term (When You Have Time)**
1. Full tokenizer/parser/evaluator split
2. Proper AST representation
3. Better error messages with position tracking
4. Consider using a parser generator (YACC/Bison style)

---

## THE GOOD NEWS

Your code is:
- âœ… Well-commented
- âœ… Mostly works
- âœ… Has test coverage
- âœ… Handles edge cases (with guards)

The architecture is just holding you back from easy growth.

---

## FINAL VERDICT

**Grade: C+**

**Strengths:**
- Functional for current scope
- Comments explain intent
- Handles many edge cases

**Critical Weaknesses:**
- God functions (eval-expr, apply-effect)
- Order-dependent implicit precedence
- String-based parsing without tokenization
- Guard explosion
- Not architected for growth

**Prognosis:**
Every new feature will get harder to add. You're already feeling this pain with the operator precedence issues.

**Recommendation:**
Spend 2-3 days doing a proper refactor to multi-phase architecture. Future you will thank present you.

